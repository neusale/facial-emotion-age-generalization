{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93HGbj9xlUSb"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.utils as Utils\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import utils as np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed Everything to reproduce results for future use cases\n",
    "def seed_everything(seed=42):\n",
    "    # Seed value for TensorFlow\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    # Seed value for NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Seed value for Python's random library\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Force TensorFlow to use single thread\n",
    "    # Multiple threads are a potential source of non-reproducible results.\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "\n",
    "    # Make sure that TensorFlow uses a deterministic operation wherever possible\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions\n",
    "from global_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN4ARoXt5Zp2"
   },
   "source": [
    "## Configurar e carregar imagens para treino dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train only the emotions present in all datasets (training and testing)\n",
    "emotions_labels = {0:'raiva',  1:'medo', 2:'alegria', 3: 'tristeza'}\n",
    "class_names = ['raiva', 'medo', 'alegria', 'tristeza']\n",
    "\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "img_depth = 3\n",
    "num_classes = len(class_names)\n",
    "print('Classes:' + str(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "LebqQpK9nlHr",
    "outputId": "7e76b0f9-d135-4729-acea-f1a6875ce718"
   },
   "outputs": [],
   "source": [
    "#Replace value of DATASET variable for each available dataset\n",
    "DATASET = 'NIMH'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uCgvX__3gqH",
    "outputId": "cc525c2c-d0b8-47a5-b7ad-39c180da9b42"
   },
   "outputs": [],
   "source": [
    "X_train = np.load('X_train_'+ DATASET + '.npy')\n",
    "y_train = np.load('Y_train_' + DATASET + '.npy') \n",
    "\n",
    "X_valid = np.load('X_valid_'+ DATASET + '.npy')\n",
    "y_valid = np.load('Y_valid_' + DATASET + '.npy') \n",
    "\n",
    "X_test = np.load('X_test_'+ DATASET + '.npy')\n",
    "y_test = np.load('Y_test_' + DATASET + '.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Slj_oZMY5oa"
   },
   "outputs": [],
   "source": [
    "#ImageDataGenerator to generate augmented images during model training \n",
    "batchSize = 20\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   brightness_range=[0.5,1.5]\n",
    ")\n",
    "\n",
    "train_datagen.fit(X_train)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   brightness_range=[0.5,1.5]\n",
    ")\n",
    "\n",
    "valid_datagen.fit(X_valid)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size = batchSize)\n",
    "valid_generator = train_datagen.flow(X_valid, y_valid, batch_size = batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate weights (class imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "classes_train = np.argmax(y_train, axis=1)\n",
    "classes = np.unique(classes_train)\n",
    "weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(classes_train), y=classes_train)\n",
    "weights = np.round(weights,6)\n",
    "class_weights = {k: v for k, v in zip(classes, weights)}\n",
    "print('Class weights:', class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models and train with added classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 - M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel('VGG16', img_height, img_width, modelType='m1', num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " modelTrained = compileAndTrain('VGG16', 'm1', DATASET, model, train_generator, valid_generator, \n",
    "                                X_train, class_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = test_model('VGG16', 'm1', DATASET, modelTrained, X_test, y_test, emotions_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 - M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel('VGG16', img_height, img_width, modelType='m2', num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " modelTrained = compileAndTrain('VGG16', 'm2', DATASET, model, train_generator, valid_generator, \n",
    "                                X_train, class_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = test_model('VGG16', 'm2', DATASET, modelTrained, X_test, y_test, emotions_labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
