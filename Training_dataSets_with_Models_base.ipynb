{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93HGbj9xlUSb"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.utils as Utils\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import utils as np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed Everything to reproduce results for future use cases\n",
    "def seed_everything(seed=42):\n",
    "    # Seed value for TensorFlow\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    # Seed value for NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Seed value for Python's random library\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Force TensorFlow to use single thread\n",
    "    # Multiple threads are a potential source of non-reproducible results.\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "\n",
    "    # Make sure that TensorFlow uses a deterministic operation wherever possible\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions\n",
    "from global_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN4ARoXt5Zp2"
   },
   "source": [
    "## Config and load images for models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train only the emotions present in all datasets (training and testing)\n",
    "emotions_labels = {0:'raiva',  1:'medo', 2:'alegria', 3: 'tristeza'}\n",
    "class_names = ['raiva', 'medo', 'alegria', 'tristeza']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "img_depth = 3\n",
    "num_classes = len(class_names)\n",
    "print('Classes:' + str(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "LebqQpK9nlHr",
    "outputId": "7e76b0f9-d135-4729-acea-f1a6875ce718"
   },
   "outputs": [],
   "source": [
    "#emotions_labels = {0:'raiva', 1:'aversão', 2:'medo', 3:'alegria', 4: 'tristeza', 5: 'surpresa', 6: 'desprezo'}\n",
    "#directories <dataset>_<emotion>, for ex., NIMH_Angry (emotion:[Angry, Happy, Sad, Fear])\n",
    "\n",
    "#Replace value of DATASET variable for each available dataset\n",
    "DATASET = 'NIMH'\n",
    "filesStru = getFiles(dataset=DATASET, crop=True, extensao='jpg')\n",
    "\n",
    "files = filesStru.files\n",
    "files_class = filesStru.files_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images for emotion\n",
    "data = {'imagem': files, 'emocao': files_class}\n",
    "df = pd.DataFrame(data)\n",
    "df['emocao'].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% images for emotion\n",
    "df['emocao'].value_counts(normalize=True, ascending=False) #.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emocao'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Yu59nLwruft7",
    "outputId": "5e3b4ad2-175a-4a4b-8c9b-78f825b0f253"
   },
   "outputs": [],
   "source": [
    "#Show some_images\n",
    "some_images(files, files_class, emotions_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_images(files, files_class, emotions_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbQ1wTeX0TFS",
    "outputId": "a753537f-984d-4b1a-93e6-dc1fe68519ab"
   },
   "outputs": [],
   "source": [
    "img_features_source = []\n",
    "img_features_source = create_features(files, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "i9VSPi_71b2i",
    "outputId": "5f75cc4d-0fa6-4fdc-aed9-23fad0582adc"
   },
   "outputs": [],
   "source": [
    "#Show image from img_features\n",
    "pyplot.imshow(img_features_source[93].astype(np.uint8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYre2y0H3bAS",
    "outputId": "2a23173f-e048-4395-e71b-8082c76957b8"
   },
   "outputs": [],
   "source": [
    "img_labels = np_utils.to_categorical(files_class,num_classes)\n",
    "img_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into Training (training and validation) and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uCgvX__3gqH",
    "outputId": "cc525c2c-d0b8-47a5-b7ad-39c180da9b42"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(img_features_source, img_labels, shuffle = True, \n",
    "                                                      stratify = img_labels, test_size = 0.20, random_state = 42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid  = train_test_split(X_train, y_train, shuffle = True, \n",
    "                       test_size = 0.25, random_state = 42)\n",
    "                       \n",
    "X_train.shape, X_valid.shape, X_test.shape, y_train.shape, y_valid.shape, y_test.shape\n",
    "        \n",
    "np.save('X_train_' + DATASET + '.npy', X_train) #salvar dados treino\n",
    "np.save('Y_train_' + DATASET + '.npy', y_train) \n",
    "\n",
    "np.save('X_valid_' + DATASET + '.npy', X_train) #salvar dados de validação\n",
    "np.save('Y_valid_' + DATASET + '.npy', y_train) \n",
    "\n",
    "np.save('X_test_' + DATASET + '.npy', X_test) #salvar dados teste \n",
    "np.save('Y_test_' + DATASET + '.npy', y_test) \n",
    "\n",
    "print(X_train.shape, X_test.shape, X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
